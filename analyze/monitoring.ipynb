{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade google-cloud-bigquery matplotlib numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import warnings\n",
    "\n",
    "PROJECT=\"\" # Enter your Google Project ID\n",
    "LOCATION=\"US\"\n",
    "DATASET=\"cromwell_monitoring\"\n",
    "DATE_RANGE=\"30 DAY\"\n",
    "MAX_GB_PROCESSED=1\n",
    "MAX_ROWS=100000\n",
    "\n",
    "warnings.filterwarnings('ignore', '.*user credentials from Google Cloud SDK.*', module='google.auth')\n",
    "\n",
    "def monitoring_query(dry_run=False):\n",
    "    client = bigquery.Client()\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=dry_run)\n",
    "    query = f\"\"\"\n",
    "        WITH metrics AS (\n",
    "          SELECT\n",
    "            instance_id,\n",
    "            TIMESTAMP_DIFF(MAX(timestamp), MIN(timestamp), SECOND) runtime_duration_sec,\n",
    "            AVG((SELECT AVG(p) FROM UNNEST(cpu_used_percent) p)) cpu_used_percent_avg,\n",
    "            MAX(mem_used_gb) mem_used_gb_max,\n",
    "            MAX(disk_used_gb[OFFSET(0)]) disk_used_gb_max,\n",
    "            AVG(disk_read_iops[OFFSET(0)]) disk_read_iops_avg,\n",
    "            AVG(disk_write_iops[OFFSET(0)]) disk_write_iops_avg\n",
    "          FROM\n",
    "            `{PROJECT}.{DATASET}.metrics`\n",
    "          WHERE\n",
    "            timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {DATE_RANGE})\n",
    "          GROUP BY\n",
    "            instance_id\n",
    "        ),\n",
    "        \n",
    "        results AS (\n",
    "            SELECT\n",
    "              r.project_id, r.zone, r.preemptible,\n",
    "              r.workflow_id, workflow_name, r.task_call_name, r.shard, r.attempt, execution_status,\n",
    "              m.start_time metadata_start_time, TIMESTAMP_DIFF(m.end_time, m.start_time, SECOND) metadata_duration_sec, runtime_duration_sec,\n",
    "              cpu_platform, r.cpu_count cpu_total_cores,\n",
    "              (r.cpu_count * cpu_used_percent_avg / 100) cpu_used_cores_avg,\n",
    "              r.mem_total_gb, mem_used_gb_max,\n",
    "              r.disk_mounts,\n",
    "              disk_types[OFFSET(0)] disk_type,\n",
    "              r.disk_total_gb[OFFSET(0)] disk_total_gb,\n",
    "              disk_used_gb_max, disk_read_iops_avg, disk_write_iops_avg,\n",
    "              (SELECT SUM(CAST(value AS FLOAT64)) FROM UNNEST(inputs) WHERE type = 'file') inputs_size_gb,\n",
    "              docker_image\n",
    "            FROM\n",
    "              `{PROJECT}.{DATASET}.runtime` r\n",
    "            JOIN\n",
    "              metrics\n",
    "            USING (instance_id)\n",
    "            JOIN\n",
    "              `{PROJECT}.{DATASET}.metadata` m\n",
    "            USING (instance_name)\n",
    "            WHERE\n",
    "              r.start_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {DATE_RANGE})\n",
    "              AND\n",
    "              m.start_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {DATE_RANGE})\n",
    "            ORDER BY\n",
    "              r.start_time DESC\n",
    "        )\n",
    "        \n",
    "        SELECT *\n",
    "        FROM results\n",
    "        WHERE RAND() < {MAX_ROWS}/(SELECT COUNT(*) FROM results)\n",
    "        AND inputs_size_gb IS NOT NULL\n",
    "    \"\"\"\n",
    "    return client.query(\n",
    "        query,\n",
    "        location=LOCATION,\n",
    "        job_config=job_config,\n",
    "    )\n",
    "\n",
    "q = monitoring_query(dry_run=True)\n",
    "gb_processed = q.total_bytes_processed / 1024**3\n",
    "if gb_processed > MAX_GB_PROCESSED:\n",
    "    print(f\"This query will process {gb_processed:.1f} GB when run. Please adjust DATE_RANGE and retry.\")\n",
    "    exit(1)\n",
    "else:\n",
    "    rows = [row for row in monitoring_query()]\n",
    "    print(f\"Sample size: {len(rows)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%config InlineBackend.figure_formats = ['png']\n",
    "\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "MIN_SAMPLE_SIZE = 5\n",
    "MIN_INPUTS_SIZE_GB = 0.1\n",
    "DISK_OFFSET_GB = 0.1\n",
    "\n",
    "CPU_HOUR_PRICE = 0.033174\n",
    "CPU_HOUR_PRICE_PREEMPT = 0.00698\n",
    "MEM_HOUR_PRICE = 0.004446\n",
    "MEM_HOUR_PRICE_PREEMPT = 0.00094\n",
    "\n",
    "MONTH_HOURS = 730\n",
    "HDD_HOUR_PRICE = 0.04 / MONTH_HOURS\n",
    "SSD_HOUR_PRICE = 0.17 / MONTH_HOURS\n",
    "LOCAL_SSD_HOUR_PRICE = 0.08 / MONTH_HOURS\n",
    "LOCAL_SSD_HOUR_PRICE_PREEMPT = 0.048 / MONTH_HOURS\n",
    "\n",
    "calls = {}\n",
    "for row in rows:\n",
    "    if row.task_call_name in calls:\n",
    "        calls[row.task_call_name].append(row)\n",
    "    else:\n",
    "        calls[row.task_call_name] = [row]\n",
    "\n",
    "def to_str(f: float):\n",
    "    return ('%f' % f).rstrip('0').rstrip('.')\n",
    "\n",
    "class Metric(Enum):\n",
    "    CPU = 1\n",
    "    MEM = 2\n",
    "    DISK = 3\n",
    "\n",
    "def get_metric_type(metric: str):\n",
    "    if metric.startswith('cpu'):\n",
    "        return Metric.CPU\n",
    "    elif metric.startswith('mem'):\n",
    "        return Metric.MEM\n",
    "    elif metric.startswith('disk'):\n",
    "        return Metric.DISK\n",
    "\n",
    "def find_best_fit(x, y, offset, m_type):\n",
    "    x = np.array(x)\n",
    "    px = np.insert(x, 0, x.min())\n",
    "    y = np.add(y, offset)\n",
    "    py = np.insert(y, 0, 2 * y.max())\n",
    "    points = np.array([px, py]).transpose()\n",
    "\n",
    "    hull = ConvexHull(points, qhull_options='QG0')\n",
    "\n",
    "    fit_x = np.linspace(x.min(), x.max(), 1000)\n",
    "    best_fit_y0 = None\n",
    "    best_fit_y = None\n",
    "    best_fit_label = None\n",
    "    best_sum = np.inf\n",
    "\n",
    "    for facet in hull.simplices[hull.good]:\n",
    "        fit = np.polyfit(hull.points[facet, 0], hull.points[facet, 1], 1)\n",
    "\n",
    "        if m_type == Metric.CPU:\n",
    "            fit = np.round(fit / 2 * 10) / 10\n",
    "        elif m_type == Metric.MEM:\n",
    "            fit = np.ceil(fit / 0.25 * 10) / 10\n",
    "        elif m_type == Metric.DISK:\n",
    "            fit = np.ceil(fit * 10) / 10\n",
    "\n",
    "        fit_yy0 = fit[0] * x + fit[1]\n",
    "        fit_yy = fit[0] * fit_x + fit[1]\n",
    "        fit_formula = f\"{fit[0]:.1f} * size(inputs, 'G') + {fit[1]:.1f}\"\n",
    "\n",
    "        if m_type == Metric.CPU:\n",
    "            thresh = 0.75\n",
    "            fit_y0 = np.array([1 if yy0 < thresh else np.round(yy0) * 2 for yy0 in fit_yy0])\n",
    "            fit_y = np.array([1 if yy < thresh else np.round(yy) * 2 for yy in fit_yy])\n",
    "            if fit_yy.max() < thresh:\n",
    "                fit_label = f'1'\n",
    "            elif fit_yy.min() > thresh:\n",
    "                if fit_y.min() == fit_y.max():\n",
    "                    fit_label = to_str(fit_y[0])\n",
    "                else:\n",
    "                    fit_label = f'round({fit_formula}) * 2'\n",
    "            else:\n",
    "                fit_label = f'if {fit_formula} < {thresh} then 1 else round({fit_formula}) * 2'\n",
    "        elif m_type == Metric.MEM:\n",
    "            thresh = 3\n",
    "            fit_y0 = np.array([1 if yy0 <= thresh else np.ceil(yy0) * 0.25 for yy0 in fit_yy0])\n",
    "            fit_y = np.array([1 if yy <= thresh else np.ceil(yy) * 0.25 for yy in fit_yy])\n",
    "            if fit_yy.max() <= thresh:\n",
    "                fit_label = f'1'\n",
    "            elif fit_yy.min() > thresh:\n",
    "                if fit_y.min() == fit_y.max():\n",
    "                    fit_label = to_str(fit_y[0])\n",
    "                else:\n",
    "                    fit_label = f'ceil({fit_formula}) * 0.25'\n",
    "            else:\n",
    "                fit_label = f'if {fit_formula} <= {thresh} then 1 else ceil({fit_formula}) * 0.25'\n",
    "        elif m_type == Metric.DISK:\n",
    "            fit_y0 = np.ceil(fit_yy0)\n",
    "            fit_y = np.ceil(fit_yy)\n",
    "            if fit_y.min() == fit_y.max():\n",
    "                fit_label = to_str(fit_y[0])\n",
    "            else:\n",
    "                fit_label = f'ceil({fit_formula})'\n",
    "\n",
    "        s = fit_y.sum()\n",
    "        if s <= best_sum:\n",
    "            best_sum = s\n",
    "            best_fit_y0 = fit_y0\n",
    "            best_fit_y = fit_y\n",
    "            best_fit_label = f'best fit: {fit_label}'\n",
    "    \n",
    "    return fit_x, best_fit_y, best_fit_y0, best_fit_label\n",
    "\n",
    "def get_price(y, preemptible, hours, units, preemptible_units):\n",
    "    yy = np.multiply(y, hours)\n",
    "    return np.multiply(yy[~preemptible], units[~preemptible]).sum() + \\\n",
    "        np.multiply(yy[preemptible], preemptible_units[preemptible]).sum()\n",
    "\n",
    "def get_disk_price(s):\n",
    "    if s.disk_type == 'HDD':\n",
    "        return HDD_HOUR_PRICE\n",
    "    elif s.disk_type == 'SSD':\n",
    "        return SSD_HOUR_PRICE\n",
    "    elif s.disk_type == 'LOCAL':\n",
    "        if s.preemptible:\n",
    "            return LOCAL_SSD_HOUR_PRICE_PREEMPT\n",
    "        else:\n",
    "            return LOCAL_SSD_HOUR_PRICE\n",
    "\n",
    "def get_price_savings(samples, total, fit, m_type):\n",
    "    preemptible = np.array([s.preemptible for s in samples])\n",
    "    hours = np.array([s.runtime_duration_sec / 3600.0 for s in samples])\n",
    "\n",
    "    if m_type == Metric.CPU:\n",
    "        price_units = np.full(len(samples), CPU_HOUR_PRICE)\n",
    "        price_units_preempt = np.full(len(samples), CPU_HOUR_PRICE_PREEMPT)\n",
    "        price_units_fit = price_units\n",
    "        price_units_fit_preempt = price_units_preempt\n",
    "    elif m_type == Metric.MEM:\n",
    "        price_units = np.full(len(samples), MEM_HOUR_PRICE)\n",
    "        price_units_preempt = np.full(len(samples), MEM_HOUR_PRICE_PREEMPT)\n",
    "        price_units_fit = price_units\n",
    "        price_units_fit_preempt = price_units_preempt\n",
    "    elif m_type == Metric.DISK:\n",
    "        price_units = np.array([get_disk_price(s) for s in samples])\n",
    "        price_units_preempt = price_units\n",
    "        price_units_fit = np.full(len(samples), HDD_HOUR_PRICE)\n",
    "        price_units_fit_preempt = price_units_fit\n",
    "\n",
    "    price_total = get_price(total, preemptible, hours, price_units, price_units_preempt)\n",
    "    price_fit = get_price(fit, preemptible, hours, price_units_fit, price_units_fit_preempt)\n",
    "    savings = price_total - price_fit\n",
    "\n",
    "    return price_total, savings\n",
    "\n",
    "def plot(i, j, samples, title, metric, total, ylabel, color, offset=0):\n",
    "    failed = [s for s in samples if s.execution_status == 'Failed']\n",
    "    done = [s for s in samples if s.execution_status == 'Done']\n",
    "\n",
    "    inputs_size_gb_all = [s.inputs_size_gb for s in samples]\n",
    "    inputs_size_gb_failed = [s.inputs_size_gb for s in failed]\n",
    "    inputs_size_gb_done = [s.inputs_size_gb for s in done]\n",
    "    \n",
    "    metric_all = [s[metric] for s in samples]\n",
    "    metric_failed = [s[metric] for s in failed]\n",
    "    metric_done = [s[metric] for s in done]\n",
    "\n",
    "    total_all = [s[total] for s in samples]\n",
    "    total_failed = [s[total] for s in failed]\n",
    "    total_done = [s[total] for s in done]\n",
    "\n",
    "    m_type = get_metric_type(metric)\n",
    "    fit_x, fit_y, fit_y0, fit_label = find_best_fit(inputs_size_gb_all, metric_all, offset, m_type)\n",
    "    spending, savings = get_price_savings(samples, total_all, fit_y0, m_type)\n",
    "\n",
    "    plt.subplot(n, 3, i * 3 + j)\n",
    "\n",
    "    if len(inputs_size_gb_failed) > 0:\n",
    "        plt.plot(inputs_size_gb_failed, metric_failed, 'o', label=f'{metric} (failure)', color='xkcd:orange')\n",
    "        plt.plot(inputs_size_gb_failed, total_failed, 'o', label=f'{total} (failure)', color='xkcd:light orange')\n",
    "\n",
    "    plt.plot(inputs_size_gb_done, metric_done, '.', label=f'{metric} (success)', color=f'xkcd:{color}')\n",
    "    plt.plot(inputs_size_gb_done, total_done, '.', label=f'{total} (success)', color=f'xkcd:light {color}')\n",
    "        \n",
    "    if fit_y is None:\n",
    "        print(f'Failed to find a fit for {metric} of \"{title}\" task call')\n",
    "    else:\n",
    "        plt.plot(fit_x, fit_y, label=fit_label)\n",
    "\n",
    "    plt.xlabel('Inputs (GB)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f'{title}: spending ~\\${spending:0.2f}, savings ~\\${savings:0.2f}')\n",
    "    plt.legend()\n",
    "\n",
    "i = 0\n",
    "n = len(calls)\n",
    "fig = plt.figure(figsize=(30, 10 * n))\n",
    "\n",
    "for name, samples in calls.items():\n",
    "    call = f'\"{name}\" task call'\n",
    "    if len(samples) < MIN_SAMPLE_SIZE:\n",
    "        print(f'Skipping {call}: sample too small')\n",
    "        continue\n",
    "    \n",
    "    if np.all([s.inputs_size_gb < MIN_INPUTS_SIZE_GB for s in samples]):\n",
    "        print(f'Skipping {call}: inputs size too small')\n",
    "        continue\n",
    "\n",
    "    plot(i, 1, samples, name, 'cpu_used_cores_avg', 'cpu_total_cores', 'CPU (cores)', 'green')\n",
    "    plot(i, 2, samples, name, 'mem_used_gb_max', 'mem_total_gb', 'Memory (GB)', 'blue')\n",
    "    plot(i, 3, samples, name, 'disk_used_gb_max', 'disk_total_gb', 'Disk (GB)', 'magenta', DISK_OFFSET_GB)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}